name: "Application"

on:
  push:
    branches: ["main"]
    paths:
      - "app/**"
      - "k8s/**"
      - ".github/**"

permissions:
  id-token: write
  contents: read
  security-events: write

jobs:
  build-and-deploy:
    name: "Build and Deploy"
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Run Gosec Security Scanner
        uses: securego/gosec@master
        with:
          args: ./app/...
        continue-on-error: true

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/GitHubActionsProvisionerRole
          aws-region: us-west-2

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build Docker image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: wiz-exercise-todo-app
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG -t $ECR_REGISTRY/$ECR_REPOSITORY:latest ./app/tasky-main

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.login-ecr.outputs.registry }}/wiz-exercise-todo-app:${{ github.sha }}
          format: "sarif"
          output: "trivy-results.sarif"
          severity: "CRITICAL,HIGH"

      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: "trivy-results.sarif"

      - name: Push Docker image to Amazon ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: wiz-exercise-todo-app
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest

      - name: Install kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: "latest"

      - name: Update Kubeconfig
        run: aws eks update-kubeconfig --name wiz-exercise-eks --region us-west-2

      - name: Deploy to EKS
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        run: |
          # 1. Get infrastructure info
          # 1. Get MongoDB Private IP
          # We filter by the Name tag and ensure it's 'running' to avoid getting IPs of terminated instances.
          MONGODB_IP=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=wiz-exercise-mongodb" "Name=instance-state-name,Values=running" \
            --query "Reservations[].Instances[].PrivateIpAddress" \
            --output text | head -n 1)

          if [ -z "$MONGODB_IP" ]; then
            echo "Error: Could not find a running MongoDB instance. Check AWS filters."
            exit 1
          fi

          echo "Found MongoDB at: $MONGODB_IP"

          # 2. Get MongoDB Password from Secrets Manager
          # Secrets Manager often appends a random suffix to names in Terraform.
          # This find-and-fetch logic ensures we get the right one.
          SECRET_NAME=$(aws secretsmanager list-secrets \
            --query "SecretList[?starts_with(Name, 'wiz-exercise/mongodb-auth')].Name" \
            --output text | awk '{print $1}')

          SECRET_JSON=$(aws secretsmanager get-secret-value \
            --secret-id "$SECRET_NAME" \
            --query SecretString --output text)

          MONGODB_PASSWORD=$(echo "$SECRET_JSON" | jq -r .password)
          MONGODB_USER=$(echo "$SECRET_JSON" | jq -r .username)

          # 2. Create namespace FIRST
          kubectl apply -f k8s/namespace.yaml

          # 3. Create secret (namespace now exists)
          kubectl create secret generic mongodb-secret \
            --namespace wiz-exercise \
            --from-literal=password="$MONGODB_PASSWORD" \
            --from-literal=username="$MONGODB_USER" \
            --dry-run=client -o yaml | kubectl apply -f -

          # 4. Replace placeholders
          #
          # Fix: Use | instead of / to avoid URI conflicts
          sed -i "s|AWS_ACCOUNT_ID.dkr.ecr.us-west-2.amazonaws.com|${ECR_REGISTRY}|g" k8s/deployment.yaml
          # Ensure you also tag with the specific SHA instead of just 'latest' for better tracking
          sed -i "s|:latest|:${{ github.sha }}|g" k8s/deployment.yaml

          sed -i "s/MONGODB_HOST_IP/${MONGODB_IP}/g" k8s/mongodb-external.yaml
          sed -i "s/MONGODB_HOST_IP/${MONGODB_IP}/g" k8s/networkpolicy.yaml

          # 5. Apply remaining manifests in dependency order
          kubectl apply -f k8s/serviceaccount.yaml
          kubectl apply -f k8s/mongodb-external.yaml
          kubectl apply -f k8s/clusterrolebinding.yaml
          kubectl apply -f k8s/service.yaml
          kubectl apply -f k8s/networkpolicy.yaml
          kubectl apply -f k8s/pdb.yaml
          kubectl apply -f k8s/deployment.yaml
          kubectl apply -f k8s/ingress.yaml

      - name: Verify Deployment
        run: |
          # Show pod status
          kubectl get pods -n wiz-exercise

          # Show service and ingress
          kubectl get svc,ingress -n wiz-exercise

      - name: Get Application URL
        run: |
          echo "Waiting for ALB to be provisioned (this may take 2-3 minutes)..."

          ALB_URL=$(kubectl get ingress todo-app-ingress -n wiz-exercise -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

          if [ -z "$ALB_URL" ]; then
            echo "⚠️  ALB not ready yet. Check ingress status with: kubectl describe ingress -n wiz-exercise"
          else
            echo "✅ Application available at: http://$ALB_URL"
          fi
